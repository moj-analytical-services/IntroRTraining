
---
title: "Intro R training"
output: word_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Basic setup

This document provides accompanying training material used in the Introduction to R Training session, conducted by the ASD R training group. Prior to joining the session, you should ensure you are set up on the Analytical Platform (IT system permitting). https://moj-analytical-services.github.io/platform_user_guidance/getting-started.html.

This guide is hosted on Github: https://github.com/moj-analytical-services/IntroRTraining

In that repository, there is the file code_participant.R, which contains code related to the exercises in this guide. The Data Science team conduct separate training sessions for working for github, but for now, please import the project from github by following the steps outlined in section 4.1.3 of the platform guidance: https://moj-analytical-services.github.io/platform_user_guidance/using-github-with-r-studio.html

## Contents

1. Introduction - in this section you will be introduced to R, the RStudio Environment and some of the basic R commands
2. Processing data - this section introduces R packages, importing data into R,  inspecting data and data classes and the ifelse function
3. Data wrangling and 'group by' calculations - this section covers the most useful data manipulation functions using the dplyr package
4. Dates - this section explores working with dates
5. Merging data, missing values and exporting - This section explores some more advanced data wrangling techniques, as well as exporting data
6. Extra resources

## 1. Introduction

### 1.1 Session aims

* Overview of R
* Get new R users up and running with confidence
* Introduce key functions needed in ASD work

### 1.2 What is R?

R is an open-source programming language and software environment, designed primarily for statistical computing. It has a long history - it is based on the S language, which was developed in 1976 in Bell Labs, where the UNIX operating system and the C and C++ languages were developed. The R language itself was developed in the 1990s, with the first stable version release in 2000.

R has grown rapidly in popularity particularly in the last five years, due to the increased interest in the data science field. It is now a key tool in the MoJ's Analytical Platform.

Some of the advantages:

* It is **popular** - there is a large, active and rapidly growing community of R programmers, which has resulted in a plethora of resources and extensions.
* It is **powerful** - the history as a statistical language means it is well suited for data analysis and manipulation.
* It is **extensible** - there are a vast array of **packages** that can be added to extend the functionality of R, produced by statisticians and programmers around the world. These can range from obscure statistical techniques to tools for making interactive charts
* It's **free and open source** - a large part of its popularity can be owed to its low cost, particularly relative to proprietary software such as SAS.

### 1.3 How is it used?

There a number of areas in the MoJ where R is making an impact:

1. The Reproducible Analytical Pipeline (RAP) is a set of tools and standards for producing our statistical publications in a more automated and reproducible way. The Offender Management Statistics Quarterly publication already runs on RAP https://github.com/moj-analytical-services/OMSQ_RAP
2. A number of webapps using Shiny have been produced, allowing customers to explore data in an interactive way. The PQ tool is a strong example: https://pq-tool.apps.alpha.mojanalytics.xyz/
3. It has enabled more technical analysis to be done with the help of packages written by academics and statisticians, which would have to be coded from scratch using SAS. For example, the PQ tool makes use of packages to facilitate Natural Language Processing and Text Mining.


### 1.4 Command console

The window in which commands are entered is called the "console" window. It is used to input and execute code. Results, errors and warnings are shown directly in the same window. 

A command which is entered into the console is executed by simply pressing enter. 

Code appears in blue text.
Results appear in black text. 
Warnings and errors appear as red text. 

```{r, include = FALSE}

### have to change the colours manually in word. Markdown doesn't allow for font colour changes without some clever HTML programming

```


For instance if you type:

```{r}
x <- 3
```


(and press return) R creates an object called x which takes the value 3. You can see this in the 'workplace' (the environment window in the top right) and if you type: 

```{r}
x 
```

The results are then shown in the console.  

Note - to assign a name to an object in R you need to use an arrow and a hyphen:
<-

Furthermore, R is case sensitive so if you were to type X, an error would be displayed as you have not yet created and object called X.

As well as storing single values, you can also create vectors. The below statement creates a vector object with the values 3, 2 and 4:

```{r}
x <- c(3, 2, 4)
```

This uses the "c" function - the c is short for "concatenate". You can now see the new object x in the 'workplace'. Note that the old object x has been overwritten and that the new object is of class numeric. 

The console will remember your most recent commands, if you want to reuse one, just use the up and down arrows to scroll through them. When you have found the one that you want, press return, R will repeat that line of code and display the results. 


### 1.5 Script file

While commands can be written into the console, it is a good idea to use a "script". This is a code file that can be saved and reused in future. 

To create a new file: click 'file', 
                              'New file',
                                'R Script'
                              
In R, these files have a '.R' extension. The code file should appear in the top left of the screen. These files can be saved and used again in future. 

To execute the code, click run at the top of the screen. R will run the line of code that the cursor is currently on, if you want to run several lines of code, highlight them and then press run.


### 1.6 Other windows and getting help

The top right panel shows all "objects" that are in your working environment. This will become clearer throughout the session but typically, this will be any data that you have created or imported, additional variables and values that you have created. For instance, if you have run the code above, 'x' should be shown here. Other objects such as regression models that you have created would also appear here. From here you can also use a drop down menu to import more data. 

The bottom right window has several tabs. You can see your files and any plots that you have created. It also shows what packages are available and what ones are loaded, more on packages later. 

There is also a help menu. You can either use this or type ? into the console and then the name of what it is you want help on in brackets. For instance, the following line would give you help on the function called 'mean':

```{r results = "hide"}
?mean
```

Of course, you can also use google or the ASD slack to try and find the solution to the problem. 


### 1.7 Exercises

1.	Create a new source code file in which you can store all commands you make during this exercise. Save it as 'Intro_R_Exercises.R'.
2.  Create a new value called y which is equal to 17.
3.  Now multiply y by 78. What answer do you get?
4.	What does the command head do?
5.	What command might you use to subset a dataset?

##   2. Processing data
### 2.1 Setting up a working directory

It can be helpful to set up a working directory so that everything we are going to import into R or export from R will be saved by default into this folder. You can check what the working directory currently is by using the getwd() command (which stands for get working directory):

```{r results="hide"}
getwd()
```

If you want to change the working directory you can use the setwd() command:

```{r}
setwd("/home")

```

### 2.2 Packages

A lot of pre-programmed routines are included in R, and you can add a lot more through packages. One characteristic that's important to recognise is that just as there are many ways of getting from Victoria Station to 102 Petty France, there are many ways of doing the same thing in R. Some ways are (computationally) faster, some are simpler to program, and some may be more conducive to your taste.  

Packages extend R's functionality enormously and are a key factor in making R so popular. For instance, to install the tidyverse package in R, use the Install button from the Packages tab in Rstudio. 

This uses the following command:

```{r eval = FALSE}
install.packages("tidyverse")
```

Once a package is installed, you should be able to see it in the packages tab. If you want to use it, you can load it by ticking the appropriate box in the packages window. You can also load packages using the library command, which you can inside your script, so they will automatically load when you run it:

```{r results=FALSE, warning=FALSE, comment=FALSE}
library("tidyverse")
```

The package tidyverse contains many useful packages such as dplyr which is a particularly useful package for manipulating and processing data. Many of the functions in the rest of this training course are from this package.

To know more about a package, it is always useful to read the associated documentation:

```{r results="hide"}
help(package=dplyr)
```


### 2.3 Importing data

It is important to be able to import data both from the analytical platform amazon server and other servers we work with.

#### Importing data not on the analytical platform amazon server

You can import data in .csv files using Rstudio by clicking on the Environment tab and then the Import Dataset button. You can then navigate to the folder where the dataset "Offenders_Chicago_Police_Dept_Main.csv" is saved and click on it. A window will then appear which will include on the bottom right a preview of your data. Here it looks good, so we can click on import. 

You can now see by looking in the 'environment' window that an object has been created (the 'offenders' dataset), and that it has 1413 observations and 9 variables.

Now look at the Console tab. You should see the commands library and read_csv() appear with the whole path to the data set. It is a good idea to copy and paste these commands inside your script, so you won't need to do this again to load the data.

Alternatively (you have already loaded the readr package as it is part of the tidyverse package - see section 2.2) you can simply use the command read_csv():

```{r eval = FALSE, results="hide"}
offenders <- read_csv("Offenders_Chicago_Police_Dept_Main.csv")
```

Note that the above assumes that the csv file is in your working directory, otherwise you will need to include the file path - see section 2.1.

#### Importing data from the analytical platform amazon server

To import the data for this session from the platform amazon server use this command:

```{r, results="hide"}

offenders <- s3tools::s3_path_to_full_df("alpha-everyone/R_training_intro/Offenders_Chicago_Police_Dept_Main.csv")

```


This assumes by default that the first line of the file contains a header (header = T) and the columns are separated by a comma symbol (sep = ",").  

There are other commands and various packages that can be used to import datasets with other extensions (e.g. .xls) e.g. see http://www.statmethods.net/input/importingdata.html 


### 2.4 Inspecting the dataset

As noted in the previous section, you can see by looking in the 'environment' window that the 'offenders' dataset has 1413 observations and 9 variables. To view this dataset, click the icon to the right of this information, which you can see from the console is the equivalent of using the command:

```{r eval = FALSE}
View(offenders)
```

To obtain a summary of the meta-data of your dataset you can click on the arrow by 'offenders' in the 'environment' window, which provides the same information as by typing the following command:

```{r}
str(offenders)
```

Looking at the output provided informs you that the dataset 'offenders' is in R terminology both a tibble and a dataframe, and as we've already seen has 1413 observations and 9 variables. Variables in a data frame are like columns in a table, and are stored as vectors. Also provided is some information about each variable (or vector) in the dataset (or dataframe) as designated by R; the name, the type (in this case either integer, number or character).  

The summary command also provides some useful details:

```{r}
summary(offenders)
```

Square brackets can be used to subset data. For instance 'offenders[ i , j ]' would return the value in the ith row and jth column of the dataframe 'offenders'. So, if you want the fourth variable for the 500th observation:

```{r}
offenders[500,4]
```

If you want the fourth variable for the 500th and 502nd observations you can use the concatenate (c) command:

```{r}
offenders[c(500, 502),4]
```

If you want the first five variables for the 500th observation:

```{r}
offenders[500,1:5]
```

The colon operator allows you to create sequences - in this case from 1 to 5, so here you will retrieve from the 1st to the 5th columns.  


### 2.5 Dataset variables 

Dataframes/tibbles in R are a collection of vectors where where each vector is a column and represents a variable. To view a specific variable, for instance gender, you use a dollar sign as follows:

```{r results="hide"}
offenders$GENDER
```

The format is dataframe name, $, variable name. Note that a vector is returned. 

To create a new variable providing the weight in kg (instead of in pounds):

```{r results="hide"}
offenders$weight_kg <- offenders$WEIGHT*0.454
```

You can see the new variable by using the View command (note that after make changes to the dataset you need to use the View command again to see the latest version):

```{r eval = FALSE}
View(offenders)
```


### 2.6 Data classes

All variables have an associated class. The class will determine what calculations are possible with them and how R should treat them. So far, our dataset offenders has variables of three different classes; integer, number, and character. Other useful types are factor, logical and date. 

We can check what class a variable is using summary, looking at the information in the Environment pane or by using the command "class"

```{r}
class(offenders$weight) 
```

It's possible to coerce variables from one class to another. We can change the weight variable in the offenders dataset to be a numeric variable as follows:

```{r results="hide"}
offenders$WEIGHT <- as.numeric(offenders$WEIGHT)
```

and back again as follows:

```{r results="hide"}
offenders$WEIGHT <- as.integer(offenders$WEIGHT) 
```

We can change the GENDER variable in the offenders dataset to be a factor variable as follows:

```{r results="hide"}
offenders$GENDER <- as.factor(offenders$GENDER)  
```

Factors are for categorical variables involving different levels. So for example, in the dataset 'offenders', FEMALE is stored as 1, and MALE as 2. We can see this now when looking at the environment tab (after clicking the arrow to the left of offenders) and also the order from using the following command:

```{r}
levels(offenders$GENDER)
```

The ordering is useful when we do regression analyses as we may want a particular category to be the reference category. By default, the first category is the reference category but this can be changed e.g. from FEMALE to MALE using the following command:

```{r}
offenders$GENDER <- relevel(offenders$GENDER, "MALE")
```

We can now change the GENDER variable in the offenders dataset back to be a character variable as follows:

```{r results="hide"}
offenders$GENDER <- as.character(offenders$GENDER)  
```

A logical variable has two values TRUE or FALSE. If you type the following:

```{r results="hide"}
offenders$tall <- offenders$HEIGHT > 175
```

Take care of the syntax here, the first arrow and hyphen are used to assign the new variable. The second arrow is to compare height with 174. In this case we are asking if the offenders height is greater than 175cm.

We can see offenders$tall is of class logical:

```{r}
class(offenders$tall)
```

### 2.7 Ifelse

The logical class is important to perform ifelse commands. These are the equivalent of If statements in Excel. We can use this, for example, to identify those with weight under 90kg in the dataset 'offenders':

```{r results="hide"}
offenders$wt_under_90  <- ifelse(offenders$weight_kg<90, 1, 0)
```


### 2.8 Some useful numeric and statistical functions include:

   - abs(x): returns the absolute value of x
   - sqrt(x): returns the square root of x
   - round(x, digits = n): rounds a number to the nth place
   - exp(x): returns the exponential of x
   - log(x): returns the natural log of x
   - sum(x): if x is a vector, returns the sum of its elements
   - min(x): if x is a vector, returns the smallest of its elements
   - max(x): if x is a vector, returns the biggest of its elements
   - rnorm(n, mean = 0, sd = 1): return n random numbers from the standard normal distribution
   - rbinom(n, no. of trials = 1, prob = 0.5): return random numbers from n coin tosses
   - mean(x): if x is a vector of observations, return the mean of its elements
   - sd(x): if x is a vector of observations, return its standard deviation
   - cor(x): gives the linear correlation coefficient
   - median(x): if x is a vector of observations, return its median


### 2.9 Exercises

1.	What are the mean, max and min for variable AGE in the dataset offenders?
2.	Create a new variable providing the number of (full) years someone is over 16.
3.	Create a new variable called 'height_under_150' which is 1 if under 150 cm and 0 otherwise.


## 3 Data wrangling and 'group by' calculations
### 3.1 Grouping and summarising data

We can produce breakdowns of statistics using the group_by and summarise commands from the dplyr package.

```{r results="hide"}
?dplyr::summarise
?group_by
```

group_by() identifies which variables we want to produce breakdowns by. 

summarise() is used to indicate which values we want to calculate. 

Using these functions together we can produce summary statistics in a similar way to pivot tables in Excel. We can use these functions together using the pipe (%>%) operator which makes code more readable and means you don't have to create a new object each time you run a command.

So if we want the mean number of previous convictions with breakdown by REGION and GENDER:

```{r results="hide"}
regional_gender_average <- offenders %>% group_by(REGION, GENDER) %>%
summarise(Ave = mean(PREV_CONVICTIONS))
```

In the above code R is taking the 'offenders' dataset, grouping it first by REGION and then by GENDER (note that the dataset being passed into the group_by command using '%>%' is instead of specifying the 'offenders' dataset as the first argument within the group_by command), and then outputting the mean number of previous convictions by REGION and GENDER. The new mean number of previous convictions variable we've decided to call 'Ave'. The results are saved into a new dataset called 'regional_gender_average'.  
There are other functions that could be used here instead of mean e.g. n, n_distinct, min, max, mean, median, var and sd 

If we want also to add a new variable called 'Count' that provides the counts by REGION and GENDER we can rerun as follows:

```{r results="hide"}
regional_gender_average <- offenders %>% group_by(REGION, GENDER) %>%
summarise(Ave = mean(PREV_CONVICTIONS), Count=n())
```

The regional_gender_average dataset is grouped by REGION and GENDER. If we want to remove this grouping we can use the ungroup command:

```{r results="hide"}
regional_gender_average <- ungroup(regional_gender_average)
```


### 3.2 Filter

If you would like to produce statistics for a subset of rows or observations, a good function to use is filter() from the dplyr package.

Let's first take a look at the different possible values of the SENTENCE variable. We can do that quickly using the group_by/summarise combination.

```{r}
offenders %>% group_by(SENTENCE) %>% summarise(Count = n())
```

To filter we just specify the data that we want to filter (offenders) and the value that we want to filter on. In this case lets filter where SENTENCE is "Court_order" and AGE is more than 50 and then recalculate the mean number of previous convictions with breakdown by REGION and GENDER:

```{r results="hide"}
crt_order_average <- offenders %>% filter(SENTENCE == "Court_order" & AGE > 50) %>% group_by(REGION, GENDER) %>%
summarise(Ave = mean(PREV_CONVICTIONS))
```


### 3.3 Select

We can also use the select() command from the dplyr package to choose just the variables from the 'offenders' dataset that we want. So if we want to create a new dataset without the names and addresses:

```{r results="hide"}
offenders_anonymous <- select(offenders, -LAST, -FIRST, -BLOCK)
```

Note (as is common with dplyr functions) we first specify the name of the dataset and then the variables that in this case we want to remove.

Let's say that now we want to restrict this dataset to just include BIRTH_DATE, WEIGHT and number of previous convictions. 

```{r results="hide"}
offenders_anonymous <- select(offenders, BIRTH_DATE, WEIGHT, PREV_CONVICTIONS)
```


### 3.4 Rename

We can rename variables using the dplyr function rename(). Let's amend our above coding in creating the 'offenders_anonymous' dataset so that BIRTH_DATE is instead called 'DoB'.

```{r results="hide"}
offenders_anonymous <- offenders %>%
  select(BIRTH_DATE, WEIGHT, PREV_CONVICTIONS) %>%
  rename(DoB = BIRTH_DATE) 
```
       
If you also wanted to rename PREV_CONVICTIONS to Num_prev_convictions to make it easier to understand then:

```{r results="hide"}
offenders_anonymous <- offenders %>%
  select(BIRTH_DATE, WEIGHT, PREV_CONVICTIONS) %>%
  rename(DoB = BIRTH_DATE, Num_prev_convictions = PREV_CONVICTIONS) 
```


### 3.5 Mutate

You can create new variables and perform calculations on variables using the dplyr command mutate().
 
```{r eval = FALSE}
?mutate
```

So if we wanted to amend our coding to include a new derived variable weight_kg in the 'offenders_anonymous' dataset: 

```{r results="hide", warning=FALSE, comment=FALSE}
offenders_anonymous <- offenders %>%
  select(BIRTH_DATE, WEIGHT, PREV_CONVICTIONS) %>%
  rename(DoB = BIRTH_DATE, Num_prev_convictions = PREV_CONVICTIONS) %>%
  mutate(weight_kg = WEIGHT * 0.454)
```

You can download the 'Data Transformation Cheat Sheet' (and other cheatsheets) at: https://www.rstudio.com/resources/cheatsheets/


### 3.6 Exercises

1.  Using group_by and summarise, calculate the average and median age for females in the West.
2.	How many have heights of less than 4 feet, what are their (recorded) heights and gender(s)?
3.	Produce a table showing the counts of height (including missing values). 
4.  Create a new dataset containing PREV_CONVICTIONS and SENTENCE variables, rename SENTENCE as sentence_type, and create a new variable num_convictions that is PREV_CONVICTIONS + 1 (to take account of the latest conviction).


## 4 Dates
### 4.1 Manipulating dates

As you might have noticed, BIRTH_DATE in the 'offenders' dataset currently has a class of character (or factor depending how you read the data in). To be able to manipulate this data as a date in R, we first need to convert it to class date.

In all of this section, we are going to use a package from tidyverse designed called lubridate, there are also ways to do the same thing using base R. First, we need to load the package:
```{r}
library(lubridate)
```

Class date involves dates being represented in R as the number of days since 1970-01-01, with negative values for earlier dates. The format is year (4 digits) - month (2 digits) - day (2 digits). You can see this if we ask R for today's date:
```{r}
today()
```

If you have a read of the help file, you'll see lubridate has a number of functions such as dmy(), myd() etc whose name models the order in which the year ('y'), month ('m') and day ('d') elements appear in the string to be parsed.

We can therefore make a new date variable (called DoB_formatted) with class date as follows, and then check the class of the new column:

```{r results="hide"}
offenders<- mutate(offenders, DoB_formatted = mdy(BIRTH_DATE))

class(offenders$DoB_formatted)

```


The function mdy() specifies the format that the date in column BIRTH_DATE is currently in so R knows where to find the day, month and year needed to create a date. 

Remember, to refer to a specific variable, we use a dollar sign. We have used a variable name that doesn't currently exist in 'offenders' so R has created a new variable and appended it.

Now we have a variable with class date we can create new variables containing just part of the date e.g.

```{r results="hide"}
offenders <- mutate(offenders, day = day(DoB_formatted))

offenders <- mutate(offenders, quarter = quarter(DoB_formatted))

offenders <- mutate(offenders, year = year(DoB_formatted))

offenders <- mutate(offenders, month = month(DoB_formatted))

offenders <- mutate(offenders, weekday = weekdays(DoB_formatted))
```

You can also calculate the number of days since a date. For instance let's say we want to know the no. of days between the date of birth and 1 Jan 2000:
```{r results="hide"}
offenders <- mutate(offenders, days_before_2000 = ymd("2000-01-01") - DoB_formatted)
```

### 4.2 Exercises

1.	Read in dataset 'FTSE_12_14.csv' and convert the variable date to class date.
(to read in the data using s3, use s3tools::s3_path_to_full_df("alpha-everyone/R_training_intro/FTSE_12_14.csv"))
2.	Add a variable called day with the day of the week, and another variable called daily_performance for how much the share price has increased or decreased that day (close price - open price). 
3.	Work out which day of the week has the highest mean performance. 

## 5 Merging data, missing values and exporting
### 5.1 Merging datasets

There are dplyr functions left_join, right_join, inner_join, full_join, semi_join and anti_join which can merge data sets, provided you have some common fields to match on. This is similar to SQL.

Let's import a new dataset which contains information on whether the offenders faced trial. 

```{r eval=FALSE, results="hide"}
offenders_trial <- read_csv("Offenders_Chicago_Police_Dept_Trial.csv")
```

Or using the platform:

```{r results="hide"}
offenders_trial  <- s3tools::s3_path_to_full_df("alpha-everyone/R_training_intro/Offenders_Chicago_Police_Dept_Trial.csv")
```

We merge the datasets with offenders using the combination of fields that together form a unique identifier. But first we need to rename DoB to BIRTH_DATE in the offenders_trial dataset:

```{r results="hide"}
offenders_trial <- dplyr::rename(offenders_trial, BIRTH_DATE=DoB) 
```

Now the variables that together form a unique identifier have the same names, we can do the merge:

```{r results="hide"}
offenders_merge <- dplyr::inner_join(offenders, offenders_trial, by=c("LAST", "BIRTH_DATE")) 
```

For more information about the different sorts of joins and other data transformation functions see the 'Data Transformation Cheat Sheet' at: https://www.rstudio.com/resources/cheatsheets/  

We can also join two datasets vertically or horizontally, using the bind_rows() or bind_cols() functions respectively. 

If we have two datasets with the same variables, we can use bind_rows to join them vertically. 

For instance:
```{r results="hide"}
men <- filter(offenders, GENDER == "MALE")
women <- filter(offenders, GENDER == "FEMALE")
rejoined <- bind_rows(men, women)
```

Note that 'rejoined' has the same number of observations and variables as 'offenders'. 

The bind_cols function does something similar but appends data horizontally. Be sure the rows align before using this function! 



### 5.2 Handling missing values

In R, missing values are represented by the symbol NA (not available). Impossible values (e.g. dividing by zero) are represented by the symbol NaN (not a number).

We can look at the HEIGHT variable as previously:

```{r results="hide"}
height_table <- offenders %>% group_by(HEIGHT) %>% summarise(Count=n())
```


Then we can view the height_table we've made which will include the number of missing values the height variable contains:
```{r eval=FALSE}
View(height_table)
```



We can also create a logical vector showing whether the row is complete (TRUE) or has a missing value in one or more columns (FALSE):

```{r results="hide"}
complete.cases(offenders)
```

Using filter we can create a new data frame just with those that are complete:

```{r results="hide"}
complete_offenders <- filter(offenders, complete.cases(offenders))
```


### 5.3 Exporting data

A command to export data into csv format is write.csv. For instance, to export our data which contains the complete cases:

```{r results="hide"}
write.csv(complete_offenders, file = "Complete_offenders.csv")
```

This assumes by default that you want to export the row headers and that the columns are separated by a comma symbol (sep = ","). The data will be saved as a CSV in your working directory.  


### 5.4 Exercises


1.	Creating a new dataset called offenders_trial_age which includes the data in offenders_trial and the age column of offenders.
2.	Export the dataset offenders_trial_age to a csv file.
3.	Using offenders create a new variable HEIGHT_NEW which is as HEIGHT except with the missing values replaced by the average height (hint: use the is.na() function). 




## 6. Extra Resources

There are lots of resources that can help you develop your R knowledge, but below are a few that are particularly helpful:

+ DataCamp is a website which hosts multiple online courses that teach coding. Their 'Introduction to R' course is free to complete and provides a broader overview in the basic concepts for coding in R. A link to the course can be found here: https://www.datacamp.com/courses/free-introduction-to-r
+ Another good resourse is the 'R for Data Science' online book: [r4ds.had.co.nz/](r4ds.had.co.nz/), written by Hadley Wickham, who is a data scientist at RStudio, who developed the tidyverse package that we introduced earlier. It gives a really good overview of R and how his package works with it.
+ RStudio has also developed a list of 'cheatsheets' which give quick overviews of the functions contained in different packages, which can be quickly referred to: https://www.rstudio.com/resources/cheatsheets/ Some can be accessed directly through the top menu help > Cheatsheets e.g. 'Data Transformation with dplyr'

For further lists of useful resources please see: https://trello.com/b/D5pSkqnT/online-analytical-training



